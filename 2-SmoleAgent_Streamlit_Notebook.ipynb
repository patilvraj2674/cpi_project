{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URVj1TlJyvzo"
      },
      "source": [
        "# Hands-On Workshop: Building AI Agents with SmolAgent and Runnint Streamlit on Colab\n",
        "\n",
        "#### **_A Step-by-Step Guide to Creating and Orchestrating AI Teams_**\n",
        "\n",
        "Presented by **Ashish Patel**   \n",
        "Date: **13 February 2024**  \n",
        "Location: **University of wollongong, GiftCity Campus, Gandhinagar, Gujarat, India**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbWclCU-hj_f",
        "outputId": "2098d5ad-d949-4fe6-83ee-98c99393daad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade -q pandas smolagents streamlit groq newspaper3k duckduckgo-search beautifulsoup4 requests nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlINktPNgUed",
        "outputId": "99f72568-d610-4cff-ceec-c05430e597a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from typing import Union, List, Dict\n",
        "from groq import Groq\n",
        "from duckduckgo_search import DDGS\n",
        "\n",
        "class DuckDuckGoSearch:\n",
        "    \"\"\"\n",
        "    Custom DuckDuckGo search implementation with robust error handling and result processing.\n",
        "    Uses the duckduckgo_search library to fetch and format news results.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        # Initialize the DuckDuckGo search session\n",
        "        self.ddgs = DDGS()\n",
        "\n",
        "    def __call__(self, query: str, max_results: int = 5) -> str:\n",
        "        try:\n",
        "            # Perform the search and get results\n",
        "            # The news method is more appropriate for recent news analysis\n",
        "            search_results = list(self.ddgs.news(\n",
        "                query,\n",
        "                max_results=max_results,\n",
        "                region='wt-wt',  # Worldwide results\n",
        "                safesearch='on'\n",
        "            ))\n",
        "\n",
        "            if not search_results:\n",
        "                return \"No results found. Try modifying your search query.\"\n",
        "\n",
        "            # Format the results into a readable string\n",
        "            formatted_results = []\n",
        "            for idx, result in enumerate(search_results, 1):\n",
        "                # Extract available fields with fallbacks for missing data\n",
        "                title = result.get('title', 'No title available')\n",
        "                snippet = result.get('body', result.get('snippet', 'No description available'))\n",
        "                source = result.get('source', 'Unknown source')\n",
        "                url = result.get('url', result.get('link', 'No link available'))\n",
        "                date = result.get('date', 'Date not available')\n",
        "\n",
        "                # Format each result with available information\n",
        "                formatted_results.append(\n",
        "                    f\"{idx}. Title: {title}\\n\"\n",
        "                    f\"   Date: {date}\\n\"\n",
        "                    f\"   Source: {source}\\n\"\n",
        "                    f\"   Summary: {snippet}\\n\"\n",
        "                    f\"   URL: {url}\\n\"\n",
        "                )\n",
        "\n",
        "            return \"\\n\".join(formatted_results)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Provide detailed error information for debugging\n",
        "            error_msg = f\"Search error: {str(e)}\\nTry again with a different search term or check your internet connection.\"\n",
        "            print(f\"DuckDuckGo search error: {str(e)}\")  # For logging\n",
        "            return error_msg\n",
        "\n",
        "class GroqLLM:\n",
        "    \"\"\"\n",
        "    LLM interface using Groq's LLama model.\n",
        "    Handles API communication and response processing.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name=\"deepseek-r1-distill-llama-70b\"):\n",
        "        self.client = Groq(api_key=\"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\")\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def __call__(self, prompt: Union[str, dict, List[Dict]]) -> str:\n",
        "        try:\n",
        "            # Convert prompt to string if it's a complex structure\n",
        "            prompt_str = str(prompt) if isinstance(prompt, (dict, list)) else prompt\n",
        "\n",
        "            # Make API call to Groq\n",
        "            completion = self.client.chat.completions.create(\n",
        "                model=self.model_name,\n",
        "                messages=[{\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt_str\n",
        "                }],\n",
        "                temperature=0.7,\n",
        "                max_tokens=1024,\n",
        "                stream=False\n",
        "            )\n",
        "\n",
        "            return completion.choices[0].message.content if completion.choices else \"Error: No response generated\"\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error generating response: {str(e)}\"\n",
        "            print(error_msg)  # For logging\n",
        "            return error_msg\n",
        "\n",
        "def create_analysis_prompt(topic: str, search_results: str) -> str:\n",
        "    \"\"\"\n",
        "    Creates a detailed prompt for news analysis, structuring the request\n",
        "    to get comprehensive and well-organized results from the LLM.\n",
        "    \"\"\"\n",
        "    return f\"\"\"Analyze the following news information about {topic}.\n",
        "    Search Results: {search_results}\n",
        "\n",
        "    Please provide a comprehensive analysis including:\n",
        "    1. Key Points Summary:\n",
        "       - Main events and developments\n",
        "       - Critical updates and changes\n",
        "\n",
        "    2. Stakeholder Analysis:\n",
        "       - Primary parties involved\n",
        "       - Their roles and positions\n",
        "\n",
        "    3. Impact Assessment:\n",
        "       - Immediate implications\n",
        "\n",
        "       - Potential long-term effects\n",
        "       - Broader context and significance\n",
        "\n",
        "    4. Multiple Perspectives:\n",
        "       - Different viewpoints on the issue\n",
        "       - Areas of agreement and contention\n",
        "\n",
        "    5. Fact Check & Reliability:\n",
        "       - Verification of major claims\n",
        "       - Consistency across sources\n",
        "       - Source credibility assessment\n",
        "\n",
        "    Please format the analysis in a clear, journalistic style with section headers.\"\"\"\n",
        "\n",
        "def log_agent_activity(prompt: str, result: str, agent_name: str):\n",
        "    \"\"\"\n",
        "    Creates an expandable log of agent activities in the Streamlit interface\n",
        "    for transparency and debugging purposes.\n",
        "    \"\"\"\n",
        "    with st.expander(\"View Agent Activity Log\"):\n",
        "        st.write(f\"### Agent Activity ({agent_name}):\")\n",
        "        st.write(\"**Input Prompt:**\")\n",
        "        st.code(prompt, language=\"text\")\n",
        "        st.write(\"**Analysis Output:**\")\n",
        "        st.code(result, language=\"text\")\n",
        "\n",
        "# Initialize Streamlit app\n",
        "st.set_page_config(page_title=\"News Analysis Tool\", layout=\"wide\")\n",
        "\n",
        "# Title and description\n",
        "st.title(\"üîç AI News Analysis Tool\")\n",
        "st.write(\"\"\"\n",
        "This tool combines the power of Groq's üê¨DeepSeek-r1 Instant model with DuckDuckGo\n",
        "search to provide in-depth news analysis. Get comprehensive insights and multiple\n",
        "perspectives on any news topic.\n",
        "\"\"\")\n",
        "\n",
        "# Initialize the components\n",
        "try:\n",
        "    # Initialize LLM and search tool\n",
        "    llm = GroqLLM()\n",
        "    search_tool = DuckDuckGoSearch()\n",
        "\n",
        "    # Input section\n",
        "    news_topic = st.text_input(\n",
        "        \"Enter News Topic or Query:\",\n",
        "        placeholder=\"E.g., Recent developments in renewable energy\"\n",
        "    )\n",
        "\n",
        "    # Analysis options\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        search_depth = st.slider(\n",
        "            \"Search Depth (number of results)\",\n",
        "            min_value=3,\n",
        "            max_value=10,\n",
        "            value=5\n",
        "        )\n",
        "    with col2:\n",
        "        analysis_type = st.selectbox(\n",
        "            \"Analysis Type\",\n",
        "            [\"Comprehensive\", \"Quick Summary\", \"Technical\", \"Simplified\"]\n",
        "        )\n",
        "\n",
        "    # Generate analysis button\n",
        "    if st.button(\"Analyze News\"):\n",
        "        if news_topic:\n",
        "            with st.spinner(\"Gathering information and analyzing...\"):\n",
        "                try:\n",
        "                    # Show search progress\n",
        "                    search_placeholder = st.empty()\n",
        "                    search_placeholder.info(\"Searching for recent news...\")\n",
        "\n",
        "                    # Perform search\n",
        "                    search_results = search_tool(\n",
        "                        f\"Latest news about {news_topic} last 7 days\",\n",
        "                        max_results=search_depth\n",
        "                    )\n",
        "\n",
        "                    if not search_results.startswith((\"Search error\", \"No results\")):\n",
        "                        # Update progress\n",
        "                        search_placeholder.info(\"Analyzing search results...\")\n",
        "\n",
        "                        # Create analysis prompt\n",
        "                        analysis_prompt = create_analysis_prompt(news_topic, search_results)\n",
        "\n",
        "                        # Get analysis from LLM\n",
        "                        analysis_result = llm(analysis_prompt)\n",
        "\n",
        "                        # Clear progress messages\n",
        "                        search_placeholder.empty()\n",
        "\n",
        "                        # Display results\n",
        "                        st.subheader(\"üìä Analysis Results\")\n",
        "                        st.markdown(analysis_result)\n",
        "\n",
        "                        # Log the activity\n",
        "                        log_agent_activity(\n",
        "                            analysis_prompt,\n",
        "                            analysis_result,\n",
        "                            \"News Analysis Agent\"\n",
        "                        )\n",
        "                    else:\n",
        "                        search_placeholder.empty()\n",
        "                        st.error(search_results)\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"An error occurred during analysis: {str(e)}\")\n",
        "        else:\n",
        "            st.warning(\"Please enter a news topic to analyze.\")\n",
        "\n",
        "    # Add helpful tips\n",
        "    with st.expander(\"üí° Tips for Better Results\"):\n",
        "        st.write(\"\"\"\n",
        "        - Be specific with your topic for more focused analysis\n",
        "        - Use keywords related to recent events for timely information\n",
        "        - Consider including timeframes in your query\n",
        "        - Try different analysis types for various perspectives\n",
        "        - For complex topics, start with a broader search and then narrow down\n",
        "        \"\"\")\n",
        "\n",
        "except Exception as e:\n",
        "    st.error(f\"\"\"\n",
        "    Failed to initialize the application: {str(e)}\n",
        "\n",
        "    Please ensure:\n",
        "    1. Your GROQ_API_KEY is properly set in environment variables\n",
        "    2. All required packages are installed:\n",
        "       - pip install streamlit groq duckduckgo-search\n",
        "    3. You have internet connectivity for DuckDuckGo searches\n",
        "    \"\"\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.caption(\n",
        "    \"Powered by Groq LLama 3.1 8B Instant, DuckDuckGo, and Streamlit | \"\n",
        "    \"Created for news analysis and research purposes\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfqlBoDvij0Q",
        "outputId": "467e622f-d471-41ff-9ad7-974b4c2f4255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K\n",
            "up to date, audited 23 packages in 2s\n",
            "\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K\n",
            "2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh6fMUJoiky7",
        "outputId": "5e1b11e3-e5ea-4ed7-ce5d-dce2bb1680a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.136.215.251:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://green-oranges-jump.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU6y63ijipJL",
        "outputId": "4c242e0e-1319-41de-89c2-8003a9a348d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.136.215.251"
          ]
        }
      ],
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jPgerUTaAAi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}